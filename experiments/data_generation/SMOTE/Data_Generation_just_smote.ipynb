{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Last Execution: 2022-04-21 18:48:07.765341\n",
      "    python:\t3.7.10\n",
      "\n",
      "    \tfastai:\t\t2.4.1\n",
      "    \tmatplotlib:\t3.5.1\n",
      "    \tnumpy:\t\t1.20.3\n",
      "    \tpandas:\t\t1.3.4\n",
      "    \tseaborn:\t0.11.2\n",
      "    \tsklearn:\t1.0.2\n",
      "    \ttorch:\t\t1.9.0\n",
      "    \tyellowbrick:\t1.3.post1\n",
      "    \timblearn:\t0.9.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path: str = '../../../Data/phase1/'   \n",
    "\n",
    "data_set: list = [ 'Traffic_type_seed.csv', 'Application_type_seed.csv']\n",
    "\n",
    "file_path       = utils.get_file_path(data_path)\n",
    "file_set : list = list(map(file_path, data_set))\n",
    "\n",
    "current_job: int  = 0\n",
    "\n",
    "utils.data_set = data_set\n",
    "utils.file_set = file_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using 2 files:\n",
      "[   '../../../Data/phase1/Traffic_type_seed.csv',\n",
      "    '../../../Data/phase1/Application_type_seed.csv']\n"
     ]
    }
   ],
   "source": [
    "print(f'We will be using {len(file_set)} files:')\n",
    "utils.pretty(file_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1/2: We now look at ../../../Data/phase1/Traffic_type_seed.csv\n",
      "\n",
      "\n",
      "Loading Dataset: ../../../Data/phase1/Traffic_type_seed.csv\n",
      "\tTo Dataset Cache: ./cache/Traffic_type_seed.csv.pickle\n",
      "\n",
      "\n",
      "        File:\t\t\t\t../../../Data/phase1/Traffic_type_seed.csv  \n",
      "        Job Number:\t\t\t1\n",
      "        Shape:\t\t\t\t(115670, 64)\n",
      "        Samples:\t\t\t115670 \n",
      "        Features:\t\t\t64\n",
      "    \n",
      "Dataset 2/2: We now look at ../../../Data/phase1/Application_type_seed.csv\n",
      "\n",
      "\n",
      "Loading Dataset: ../../../Data/phase1/Application_type_seed.csv\n",
      "\tTo Dataset Cache: ./cache/Application_type_seed.csv.pickle\n",
      "\n",
      "\n",
      "        File:\t\t\t\t../../../Data/phase1/Application_type_seed.csv  \n",
      "        Job Number:\t\t\t2\n",
      "        Shape:\t\t\t\t(113620, 64)\n",
      "        Samples:\t\t\t113620 \n",
      "        Features:\t\t\t64\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "traffic_dataset : dict = utils.examine_dataset(1)\n",
    "application_dataset : dict = utils.examine_dataset(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_smote(df: utils.pd.DataFrame, target_label: str, ratio_dict: dict) -> list:\n",
    "    '''\n",
    "        Function creates and visualizes SMOTE with the given ratio\n",
    "        Parameters:\n",
    "            df: dataframe to be used for SMOTE\n",
    "            target_label: the label used for prediction\n",
    "            ratio_dict: dictionary of the ratio to be used for SMOTE for each class\n",
    "            categorical_features: indices of the categorical features\n",
    "    '''\n",
    "    \n",
    "    X = df.drop(target_label, axis=1)\n",
    "    y = df[target_label]\n",
    "    model = utils.SMOTENC([0,62],sampling_strategy=ratio_dict)\n",
    "    X, y = model.fit_resample(X, y)\n",
    "    counter = utils.Counter(y)\n",
    "    for k,v in counter.items():\n",
    "        per = v / len(y) * 100\n",
    "        print('Class=%s, n=%d (%.3f%%)' % (k, v, per))\n",
    "\n",
    "    smote_samples = utils.pd.concat([X, utils.pd.DataFrame(y)], axis=1)\n",
    "    # now we remove every row in smote_samples that is in df\n",
    "\n",
    "    smote_without_df = smote_samples[~smote_samples.isin(df).any(axis=1)]\n",
    "        \n",
    "\n",
    "\n",
    "    # smote_samples = utils.pd.concat([df, smote_samples]).drop_duplicates()\n",
    "    return smote_without_df\n",
    "\n",
    "def get_largest_class_sample_size(df: utils.pd.DataFrame, column_name: str) -> int:\n",
    "    '''\n",
    "        Function returns the largest class sample size\n",
    "    '''\n",
    "    return df.groupby(column_name).size().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_filter_new_model(model: utils.Model_data, column_name: str, value: str, prune_column: str = None) -> utils.Model_data:\n",
    "    '''\n",
    "        Function returns a new model with the given column name and value\n",
    "    '''\n",
    "    new_model : dict = utils.copy.deepcopy(model)\n",
    "    \n",
    "    new_model['Dataset'] = model[\"Dataset\"][model[\"Dataset\"][column_name] == value]\n",
    "\n",
    "    if prune_column is not None:\n",
    "        new_model['Dataset'] = utils.prune_dataset(new_model, [prune_column])\n",
    "    return new_model\n",
    "\n",
    "def downsample(df: utils.pd.DataFrame, column_name: str, size : int) -> utils.pd.DataFrame:\n",
    "    '''\n",
    "        Function returns a new dataframe with the given column name and value\n",
    "    '''\n",
    "    return df.groupby(column_name, group_keys=False).apply(lambda df: df.sample(size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Traffic Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling to the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpn_experiment_majority_class : utils.Model_data = create_and_filter_new_model(traffic_dataset, \"Traffic Type\", 'VPN')\n",
    "tor_experiment_majority_class : utils.Model_data = create_and_filter_new_model(traffic_dataset, \"Traffic Type\", 'Tor')\n",
    "regular_experiment_majority_class : utils.Model_data = create_and_filter_new_model(traffic_dataset, \"Traffic Type\", 'Regular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=VPN, n=92659 (33.333%)\n",
      "Class=Tor, n=92659 (33.333%)\n",
      "Class=Regular, n=92659 (33.333%)\n"
     ]
    }
   ],
   "source": [
    "largest_class = get_largest_class_sample_size(traffic_dataset['Dataset'], 'Traffic Type')\n",
    "ratio_dict = {\"VPN\": largest_class, \"Regular\": largest_class, \"Tor\": largest_class}\n",
    "fake_df_traffic_majority_class = create_smote(utils.pd.concat([vpn_experiment_majority_class['Dataset'],tor_experiment_majority_class['Dataset'],regular_experiment_majority_class['Dataset']]),\n",
    "                                                            'Traffic Type', ratio_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df_traffic_majority_class.to_csv('../../../Data/phase2/smote_fake_traffic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Application Type Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def downsample_and_run_smote(dataset : dict, ratio_dict: dict, target_label: str) -> utils.pd.DataFrame:\n",
    "    models : list = []\n",
    "    df : utils.Dataframe = utils.pd.DataFrame()\n",
    "    for key, value in ratio_dict.items():\n",
    "        models.append(create_and_filter_new_model(dataset, target_label, key))\n",
    "        if len(models[-1]['Dataset']) > value:\n",
    "            models[-1]['Dataset'] = downsample(models[-1]['Dataset'], target_label, value)\n",
    "        df = df.append(models[-1]['Dataset'])\n",
    "    return create_smote(df, target_label, ratio_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling to the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=audio-streaming, n=48020 (12.500%)\n",
      "Class=browsing, n=48020 (12.500%)\n",
      "Class=chat, n=48020 (12.500%)\n",
      "Class=file-transfer, n=48020 (12.500%)\n",
      "Class=email, n=48020 (12.500%)\n",
      "Class=p2p, n=48020 (12.500%)\n",
      "Class=video-streaming, n=48020 (12.500%)\n",
      "Class=voip, n=48020 (12.500%)\n"
     ]
    }
   ],
   "source": [
    "largest_class = get_largest_class_sample_size(application_dataset['Dataset'], 'Application Type')\n",
    "\n",
    "fake_df_application_majority = downsample_and_run_smote(application_dataset, {\"audio-streaming\": largest_class, \"browsing\": largest_class, \"chat\": largest_class, \"file-transfer\": largest_class, \"email\": largest_class,\n",
    "                                                                             \"p2p\": largest_class, \"video-streaming\": largest_class, \"voip\": largest_class}, 'Application Type')\n",
    "\n",
    "fake_df_application_majority.to_csv('../../../Data/phase2/smote_fake_application.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162307, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_df_traffic_majority_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270540, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_df_application_majority.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Execution: 2022-04-21 19:09:49.950392\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Nothing after this point is included in the study",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-60961c35a1dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Last Execution: {utils.datetime.datetime.now()}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Nothing after this point is included in the study'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: Nothing after this point is included in the study"
     ]
    }
   ],
   "source": [
    "print(f'Last Execution: {utils.datetime.datetime.now()}')\n",
    "assert False, 'Nothing after this point is included in the study'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c11ee216d7ec577d195a10435e0960b194de760ba863ebf1d28b00dc7c22c397"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
