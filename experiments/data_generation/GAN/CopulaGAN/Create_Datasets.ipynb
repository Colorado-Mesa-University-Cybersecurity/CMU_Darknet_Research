{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_1: str = '../../../../Data/phase2'   \n",
    "data_path_2: str = '../../../../Data/phase1/'  \n",
    " \n",
    "\n",
    "data_set_1: list = [ 'copulagan_application_dataset_50k.csv', \n",
    "                     'copulagan_traffic_dataset_100k.csv',\n",
    "                    ]\n",
    "\n",
    "data_set_2: list = [ 'Traffic_type_seed.csv', 'Application_type_seed.csv' ] \n",
    "\n",
    "\n",
    "file_path_1       = utils.get_file_path(data_path_1)\n",
    "file_path_2       = utils.get_file_path(data_path_2)\n",
    "file_set_1 : list = list(map(file_path_1, data_set_1))\n",
    "file_set_2 : list = list(map(file_path_2, data_set_2))\n",
    "\n",
    "file_set : list   = file_set_1 + file_set_2 \n",
    "data_set   : list = data_set_1 + data_set_2 \n",
    "current_job: int  = 0\n",
    "\n",
    "utils.data_set = data_set\n",
    "utils.file_set = file_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using 4 files:\n",
      "[   '../../../../Data/phase2/copulagan_application_dataset_50k.csv',\n",
      "    '../../../../Data/phase2/copulagan_traffic_dataset_100k.csv',\n",
      "    '../../../../Data/phase1/Traffic_type_seed.csv',\n",
      "    '../../../../Data/phase1/Application_type_seed.csv']\n"
     ]
    }
   ],
   "source": [
    "print(f'We will be using {len(file_set)} files:')\n",
    "utils.pretty(file_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1/4: We now look at ../../../../Data/phase2/copulagan_application_dataset_50k.csv\n",
      "\n",
      "\n",
      "Loading Dataset: ../../../../Data/phase2/copulagan_application_dataset_50k.csv\n",
      "\tTo Dataset Cache: ./cache/copulagan_application_dataset_50k.csv.pickle\n",
      "\n",
      "\n",
      "        File:\t\t\t\t../../../../Data/phase2/copulagan_application_dataset_50k.csv  \n",
      "        Job Number:\t\t\t1\n",
      "        Shape:\t\t\t\t(400000, 65)\n",
      "        Samples:\t\t\t400000 \n",
      "        Features:\t\t\t65\n",
      "    \n",
      "Dataset 2/4: We now look at ../../../../Data/phase2/copulagan_traffic_dataset_100k.csv\n",
      "\n",
      "\n",
      "Loading Dataset: ../../../../Data/phase2/copulagan_traffic_dataset_100k.csv\n",
      "\tTo Dataset Cache: ./cache/copulagan_traffic_dataset_100k.csv.pickle\n",
      "\n",
      "\n",
      "        File:\t\t\t\t../../../../Data/phase2/copulagan_traffic_dataset_100k.csv  \n",
      "        Job Number:\t\t\t2\n",
      "        Shape:\t\t\t\t(300000, 65)\n",
      "        Samples:\t\t\t300000 \n",
      "        Features:\t\t\t65\n",
      "    \n",
      "Dataset 3/4: We now look at ../../../../Data/phase1/Traffic_type_seed.csv\n",
      "\n",
      "\n",
      "Loading Dataset: ../../../../Data/phase1/Traffic_type_seed.csv\n",
      "\tTo Dataset Cache: ./cache/Traffic_type_seed.csv.pickle\n",
      "\n",
      "\n",
      "        File:\t\t\t\t../../../../Data/phase1/Traffic_type_seed.csv  \n",
      "        Job Number:\t\t\t3\n",
      "        Shape:\t\t\t\t(115670, 64)\n",
      "        Samples:\t\t\t115670 \n",
      "        Features:\t\t\t64\n",
      "    \n",
      "Dataset 4/4: We now look at ../../../../Data/phase1/Application_type_seed.csv\n",
      "\n",
      "\n",
      "Loading Dataset: ../../../../Data/phase1/Application_type_seed.csv\n",
      "\tTo Dataset Cache: ./cache/Application_type_seed.csv.pickle\n",
      "\n",
      "\n",
      "        File:\t\t\t\t../../../../Data/phase1/Application_type_seed.csv  \n",
      "        Job Number:\t\t\t4\n",
      "        Shape:\t\t\t\t(113620, 64)\n",
      "        Samples:\t\t\t113620 \n",
      "        Features:\t\t\t64\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "copulagan_application_dataset_labels_50 = utils.examine_dataset(1)\n",
    "copulagan_traffic_dataset_100 = utils.examine_dataset(2)\n",
    "baseline_traffic_seed = utils.examine_dataset(3)\n",
    "baseline_application_seed = utils.examine_dataset(4)\n",
    "\n",
    "copulagan_traffic_dataset_100['Dataset'] = copulagan_traffic_dataset_100['Dataset'].drop(['Unnamed: 0'], axis = 1)\n",
    "copulagan_application_dataset_labels_50['Dataset'] = copulagan_application_dataset_labels_50['Dataset'].drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df: utils.pd.DataFrame, column_name: str, expected_sizes: dict) -> utils.pd.DataFrame():\n",
    "    '''\n",
    "        Function returns a new dataframe with the given column name and value\n",
    "    '''\n",
    "    new_dict = utils.pd.DataFrame()\n",
    "    for item in df[column_name].unique():\n",
    "        matching_values = df.loc[df[column_name] == item]\n",
    "        if df[column_name].value_counts()[item] > expected_sizes[item]:\n",
    "            new_dict = utils.pd.concat([new_dict, matching_values.sample(n = expected_sizes[item])])\n",
    "        else:\n",
    "            new_dict = utils.pd.concat([new_dict, matching_values])\n",
    "    return new_dict\n",
    "\n",
    "def random_sample(df: utils.pd.DataFrame, column_name: str, element_name: str, size : int) -> utils.pd.DataFrame():\n",
    "    '''\n",
    "        Function returns a new dataframe with the given column name and value\n",
    "    '''\n",
    "    new_df = df.loc[df[column_name] == element_name]\n",
    "    return new_df.sample(n = size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Type Datasets Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_sizes = {\"Regular\" : 30000, \"VPN\" : 20000, \"Tor\": 10000}\n",
    "copulagan_balanced_traffic_labels_dataset_30_20_10 = downsample(baseline_traffic_seed['Dataset'], 'Traffic Type', expected_sizes)\n",
    "copulagan_balanced_traffic_labels_dataset_30_20_10 = utils.pd.concat([copulagan_balanced_traffic_labels_dataset_30_20_10, random_sample(copulagan_traffic_dataset_100['Dataset'], 'Traffic Type', 'Tor', 10000 - baseline_traffic_seed['Dataset']['Traffic Type'].value_counts()['Tor'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_sizes = {\"Regular\" : 92659, \"VPN\" : 92659, \"Tor\": 92659}\n",
    "copulagan_balanced_traffic_labels_dataset_equal = downsample(baseline_traffic_seed['Dataset'], 'Traffic Type', expected_sizes)\n",
    "copulagan_balanced_traffic_labels_dataset_equal = utils.pd.concat([copulagan_balanced_traffic_labels_dataset_equal, random_sample(copulagan_traffic_dataset_100['Dataset'], 'Traffic Type', 'VPN', 92659 - baseline_traffic_seed['Dataset']['Traffic Type'].value_counts()['VPN'])])\n",
    "copulagan_balanced_traffic_labels_dataset_equal = utils.pd.concat([copulagan_balanced_traffic_labels_dataset_equal, random_sample(copulagan_traffic_dataset_100['Dataset'], 'Traffic Type', 'Tor', 92659 - baseline_traffic_seed['Dataset']['Traffic Type'].value_counts()['Tor'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application Types Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_sizes = {\"p2p\" : 30000, \"browsing\" : 30000, \"audio-streaming\": 30000, 'file-transfer' : 30000, 'chat': 30000, 'video-streaming': 30000, 'voip': 30000, 'email': 30000}\n",
    "copulagan_balanced_application_dataset_labels_30_30_30 = downsample(baseline_application_seed['Dataset'], 'Application Type', expected_sizes)\n",
    "copulagan_balanced_application_dataset_labels_30_30_30 = utils.pd.concat([copulagan_balanced_application_dataset_labels_30_30_30, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'audio-streaming', 30000 - baseline_application_seed['Dataset']['Application Type'].value_counts()['audio-streaming'])])\n",
    "copulagan_balanced_application_dataset_labels_30_30_30 = utils.pd.concat([copulagan_balanced_application_dataset_labels_30_30_30, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'file-transfer', 30000 - baseline_application_seed['Dataset']['Application Type'].value_counts()['file-transfer'])])\n",
    "copulagan_balanced_application_dataset_labels_30_30_30 = utils.pd.concat([copulagan_balanced_application_dataset_labels_30_30_30, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'chat', 30000 - baseline_application_seed['Dataset']['Application Type'].value_counts()['chat'])])\n",
    "copulagan_balanced_application_dataset_labels_30_30_30 = utils.pd.concat([copulagan_balanced_application_dataset_labels_30_30_30, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'video-streaming', 30000 - baseline_application_seed['Dataset']['Application Type'].value_counts()['video-streaming'])])\n",
    "copulagan_balanced_application_dataset_labels_30_30_30 = utils.pd.concat([copulagan_balanced_application_dataset_labels_30_30_30, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'voip', 30000 - baseline_application_seed['Dataset']['Application Type'].value_counts()['voip'])])\n",
    "copulagan_balanced_application_dataset_labels_30_30_30 = utils.pd.concat([copulagan_balanced_application_dataset_labels_30_30_30, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'email', 30000 - baseline_application_seed['Dataset']['Application Type'].value_counts()['email'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_sizes = {\"p2p\" : 48020, \"browsing\" : 48020, \"audio-streaming\": 48020, 'file-transfer' : 48020, 'chat': 48020, 'video-streaming': 48020, 'voip': 48020, 'email': 48020}\n",
    "copulagan_balanced_application_dataset_labels_equal = downsample(baseline_application_seed['Dataset'], 'Application Type', expected_sizes)\n",
    "copulagan_balanced_application_dataset_labels_equal = utils.pd.concat([copulagan_balanced_application_dataset_labels_equal, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'audio-streaming', 48020 - baseline_application_seed['Dataset']['Application Type'].value_counts()['audio-streaming'])])\n",
    "copulagan_balanced_application_dataset_labels_equal = utils.pd.concat([copulagan_balanced_application_dataset_labels_equal, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'file-transfer', 48020 - baseline_application_seed['Dataset']['Application Type'].value_counts()['file-transfer'])])\n",
    "copulagan_balanced_application_dataset_labels_equal = utils.pd.concat([copulagan_balanced_application_dataset_labels_equal, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'chat', 48020 - baseline_application_seed['Dataset']['Application Type'].value_counts()['chat'])])\n",
    "copulagan_balanced_application_dataset_labels_equal = utils.pd.concat([copulagan_balanced_application_dataset_labels_equal, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'video-streaming', 48020 - baseline_application_seed['Dataset']['Application Type'].value_counts()['video-streaming'])])\n",
    "copulagan_balanced_application_dataset_labels_equal = utils.pd.concat([copulagan_balanced_application_dataset_labels_equal, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'voip', 48020 - baseline_application_seed['Dataset']['Application Type'].value_counts()['voip'])])\n",
    "copulagan_balanced_application_dataset_labels_equal = utils.pd.concat([copulagan_balanced_application_dataset_labels_equal, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'email', 48020 - baseline_application_seed['Dataset']['Application Type'].value_counts()['email'])])\n",
    "copulagan_balanced_application_dataset_labels_equal = utils.pd.concat([copulagan_balanced_application_dataset_labels_equal, random_sample(copulagan_application_dataset_labels_50['Dataset'], 'Application Type', 'browsing', 48020 - baseline_application_seed['Dataset']['Application Type'].value_counts()['browsing'])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "copulagan_balanced_traffic_labels_dataset_30_20_10.to_csv('./synthetic/copulagan_traffic_30_20_10.csv', index=False)\n",
    "copulagan_balanced_traffic_labels_dataset_equal.to_csv('./synthetic/copulagan_traffic_upsample_to_majority.csv', index=False)\n",
    "copulagan_balanced_application_dataset_labels_30_30_30.to_csv('./synthetic/copulagan_application_30000.csv', index=False)\n",
    "copulagan_balanced_application_dataset_labels_equal.to_csv('./synthetic/copulagan_application_upsample_to_majority.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Execution: 2022-05-01 09:13:53.267341\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Nothing after this point is included in the study",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/drake/projects/Sp22/CMUDarknet/experiments/data_generation/GAN/CopulaGAN/Create_Datasets.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/drake/projects/Sp22/CMUDarknet/experiments/data_generation/GAN/CopulaGAN/Create_Datasets.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLast Execution: \u001b[39m\u001b[39m{\u001b[39;00mutils\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/drake/projects/Sp22/CMUDarknet/experiments/data_generation/GAN/CopulaGAN/Create_Datasets.ipynb#ch0000012?line=1'>2</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mNothing after this point is included in the study\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Nothing after this point is included in the study"
     ]
    }
   ],
   "source": [
    "print(f'Last Execution: {utils.datetime.datetime.now()}')\n",
    "assert False, 'Nothing after this point is included in the study'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c11ee216d7ec577d195a10435e0960b194de760ba863ebf1d28b00dc7c22c397"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
